### 一、计算机指令

> 让我们试试用纸带编程

#### 1.cpu Central Processing Unit 中央处理器

硬件角度：CPU就是一个超大规模集成电路，通过电路实现了加法、乘法及各种各样的处理逻辑

软件角度：CPU 就是一个执行各种计算指令（instruction Code）的逻辑机器。(计算机指令即机器语言 Machine Language)

不同的CPU，如Intel的CPU、苹果手机的ARM 的CPU 各自支持不用的计算机指令集 Instruction Set。

一个计算机程序由成千上万条指令组成。但是CPU不能一直放着所有指令，所以计算机程序平时是存储在存储器中。这种程序指令存储在存储器里面的计算机，叫作**存储程序型计算机**  Stored-program Computer

#### 2.从编译到汇编

C语言->汇编语言 ASM(Assembly Language)-> 机器语言 Machine Code>

> 汇编代码其实就是“给程序员看的机器码"

```
// 编译c语言
gcc -g -c test.c
//windows
objdump -d -M intel -S test.o
//mac
objdump -d -S test.o  // 注意-S -s 不同
// mac 编程
objdump -d -S  -x86-asm-syntax=intel test.o
```

>  objdump 为反汇编工具
>
> assembly language asm 汇编语言
>
> 每一种 CPU 的机器指令都是不一样的，因此对应的汇编语言也不一样目前最常见的 x86 汇编语言，即 Intel 公司的 CPU 使用的那一种。
>
> **汇编语言是二进制指令的文本形式**，与指令是一一对应的关系。比如，加法指令`00000011`写成汇编语言就是 ADD。只要还原成二进制，汇编语言就可以被 CPU 直接执行，所以它是最底层的低级语言

#### 3.解析指令和机器码

##### 1.常见的指令

###### 1.算数类指令

我们的加减乘除，在CPU层面，都会变成一条条算数类指令

###### 2.数据传输类指令

给变量赋值、在内存里读写数据，用的都是数据传输类指令

###### 3.逻辑类指令

逻辑上的与或非，都是这一类指令

###### 4.条件分支类指令

日常我们写的`if/else` ，其实都是条件分类指令

###### 5.无条件跳转指令

![image-20210512094624347](/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210512094624347.png)

##### 2.MIPS

>  深入研究CPU和指令集推荐 MIPS https://www.mips.com/mipsopen/

![image-20210512095158392](/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210512095158392.png)

MIPS 的指令是一个 32 位的整数，高 6 位叫操作码（Opcode），也就是代表这条指令具体是一条什么样的指令，剩下的 26 位有三种格式，分别是 R、I 和 J。

**R 指令**是一般用来做算术和逻辑操作，里面有读取和写入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。

**I 指令**则通常是用在数据传输、条件分支，以及在运算的时候使用的并非变量还是常数的时候。这个时候，没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或者一个常数。

**J 指令**就是一个跳转指令，高 6 位之外的 26 位都是一个跳转后的地址。

以加法算术指令`add $t0,$s2,$s1`为例：

为了方便，我们下面都用十进制来表示对应的代码。

对应的 MIPS 指令里 opcode 是 0，rs 代表第一个寄存器 s1 的地址是 17，rt 代表第二个寄存器 s2 的地址是 18，rd 代表目标的临时寄存器 t0 的地址，是 8。因为不是位移操作，所以位移量是 0。把这些数字拼在一起，就变成了一个 MIPS 的加法指令。

为了读起来方便，我们一般把对应的二进制数，用 16 进制表示出来。在这里，也就是 0X02324020。这个数字也就是这条指令对应的机器码。

![image-20210512100854543](/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210512100854543.png)

如果我们用打孔代表 1，没有打孔代表 0，用 4 行 8 列代表一条指令来打一个穿孔纸带，那么这条命令大概就长这样：

<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210512101129887.png" alt="image-20210512101129887" style="zoom:20%;" />

### 二、指令跳转

> 原来if..else 就是goto

#### 1.CPU是如何执行指令的

逻辑上，CPU其实由一堆寄存器组成的。寄存器就是CPU内部，由多个触发器（Flip-Flop）或者锁存器（Latches）组成的简单电路。

**触发器和锁存器，其实就是两种不同原理的数字电路组成的逻辑门（选学）。**

N 个触发器或者锁存器，就可以组成一个 N 位（Bit）的寄存器，能够保存 N 位的数据。比方说，我们用的 64 位 Intel 服务器，寄存器就是 64 位的。

#### 2.寄存器种类

一个 CPU 里面会有很多种不同功能的寄存器，三种比较特殊为：

##### 1.PC 寄存器 Program Counter Register 

也叫指令地址寄存器，用来存放下一条需要执行的计算机指令的内存地址。

##### 2.指令寄存器 Instruction Register

用来存放当前正在执行的指令。

##### 3.条件码寄存器 Status Register

用里面的一个一个标记位（Flag），存放CPU进行算术 或者 逻辑计算的结果。

##### 4.其它各种寄存器

除了这些特殊的寄存器，CPU 里面还有更多用来存储数据和内存地址的寄存器。这样的寄存器通常一类里面不止一个。我们通常根据存放的数据内容来给它们取名字，比如整数寄存器、浮点数寄存器、向量寄存器和地址寄存器等等。有些寄存器既可以存放数据，又能存放地址，我们就叫它通用寄存器。



<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210512110529712.png" alt="image-20210512110529712" style="zoom:20%;" />



实际上，一个程序执行的时候，CPU 会根据 PC 寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载。而有些特殊指令，比如上一讲我们讲到 J 类指令，也就是跳转指令，会修改 PC 寄存器里面的地址值。这样，下一条要执行的指令就不是从内存里面顺序加载的了。事实上，这些跳转指令的存在，也是我们可以在写程序的时候，使用 if…else 条件语句和 while/for 循环语句的原因

> IP 寄存器 即 指令寄存器
>
> 段寄存器：CS、DS、SS、ES

> objdump  反汇编c语言字节码、查看if/else 、for/while循环、switch...case 
>
> 《深入理解计算机系统》的第 3 章，详细讲解了 C 语言和 Intel CPU 的汇编语言以及指令的对应关系，以及 Intel CPU 的各种寄存器和指令集

##### 5.寄存器是什么？

CPU 本身只负责运算，不负责储存数据。数据一般都储存在内存之中，CPU 要用的时候就去内存读写数据。但是，CPU 的运算速度远高于内存的读写速度，为了避免被拖慢，CPU 都自带一级缓存和二级缓存。基本上，CPU 缓存可以看作是读写速度较快的内存。

但是，CPU 缓存还是不够快，另外数据在缓存里面的地址是不固定的，CPU 每次读写都要寻址也会拖慢速度。因此，除了缓存之外，CPU 还自带了寄存器（register），用来储存最常用的数据。也就是说，那些最频繁读写的数据（比如循环变量），都会放在寄存器里面，CPU 优先读写寄存器，再由寄存器跟内存交换数据。

寄存器不依靠地址区分数据，而依靠名称。每一个寄存器都有自己的名称，我们告诉 CPU 去具体的哪一个寄存器拿数据，这样的速度是最快的。有人比喻寄存器是 CPU 的零级缓存。

![image-20210512162124339](/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210512162124339.png)

### 三、函数调用

> 为什么会发生stack overflow？

#### 1.为什么我们需要程序栈？

Stack 是由内存区域的结束地址开始，从高位（地址）向低位（地址）分配。

1. 不跳转回到原来开始的地方，来实现函数的调用呢?

   把调用的函数指令，直接插入在调用函数的地方，替换掉对应的 call 指令，然后在编译器编译代码的时候，直接就把函数调用变成对应的指令替换掉。

   这样会出现问题：如果函数 A 调用了函数 B，然后函数 B 再调用函数 A，我们就得面临在 A 里面插入 B 的指令，然后在 B 里面插入 A 的指令，这样就会产生无穷无尽地替换

2. 把要跳回来执行的指令地址给记录下来呢？

   可以专门设立一个“程序调用寄存器”，来存储接下来要跳转回来执行的指令地址。等到函数调用结束，从这个寄存器里取出地址，再跳转到这个记录的地址，继续执行就好了。

​       这样会出现问题：在多层函数调用里，简单只记录一个地址也是不够的。我们在调用函数 A 之后，A 还可以调用函数 B，B 还能调用函数 C。这一层又一层的调用并没有数量上的限制。在所有函数调用返回之前，每一次调用的返回地址都要记录下来，但是我们 CPU 里的寄存器数量并不多。像我们一般使用的 Intel i7 CPU 只有 16 个 64 位寄存器，调用的层数一多就存不下了。

3. 最终方法

   在内存里面开辟一段空间，用栈这个**后进先出**（LIFO，Last In First Out）的数据结构。每次程序调用函数之前，把调用返回后的地址**压栈** 操作。如果函数执行完了，**出栈**，根据地址把程序跳转过去，就返回到了函数调用后的下一条指令了。

在真实的程序里，压栈的不只有函数调用完成后的返回地址。比如函数 A 在调用 B 的时候，需要传输一些参数数据，这些参数数据在寄存器不够用的时候也会被压入栈中。整个函数 A 所占用的所有内存空间，就是函数 A 的栈帧（Stack Frame）。Frame 在中文里也有“相框”的意思，所以，每次到这里，我都有种感觉，整个函数 A 所需要的内存空间就像是被这么一个“相框”给框了起来，放在了栈里面。

而实际的程序栈布局，**底在最上面，顶在最下面，这样的布局是因为栈底的内存地址是在一开始就固定的。而一层层压栈之后，栈顶的内存地址是在逐渐变小而不是变大。**

#### 2.如何利用函数内联进行性能优化？

把一个实际调用的函数产生的指令，直接插入到的位置，来替换对应的函数调用指令。尽管这个通用的函数调用方案，是有问题的，但是如果被调用的函数里，没有调用其他函数，这个方法还是可以行得通的。

事实上，这就是一个常见的编译器进行自动优化的场景，我们通常叫函数内联（Inline）。我们只要在 GCC 编译的时候，加上对应的一个让编译器自动优化的参数 -O，编译器就会在可行的情况下，进行这样的指令替换。

除了依靠编译器的自动优化，你还可以在定义函数的地方，加上 inline 的关键字，来提示编译器对函数进行内联。

##### 1.内联的优化

CPU 需要执行的指令数变少了，根据地址跳转的过程不需要了，压栈和出栈的过程也不用了。

##### 2.内联的代价

内联意味着，我们把可以复用的程序指令在调用它的地方完全展开了。如果一个函数在很多地方都被调用了，那么就会展开很多次，整个程序占用的空间就会变大了。

> 这样没有调用其他函数，只会被调用的函数，我们一般称之为叶子函数（或叶子过程）。
>
> 可以仔细读一下《深入理解计算机系统（第三版）》的 3.7 小节《过程》，进一步了解函数调用是怎么回事。
>
> 寄存器 和 内存，是在硬件层面就是放在不同的位置，使用不同的物理硬件来实现的。
>
> 而栈是一个抽象概念，实际是存放在内存里面的。栈是用来管理函数调用的“现场”的。确保函数调用完成后，还能回到调用者那里。

### 四、ELF和静态链接

> 为什么程序无法同时在Linux 和 Windows 下运行

#### 1.编译、链接和装载： 拆解程序执行

**C语言代码-> 汇编代码->机器码** 这个过程，计算机进行的时候是由两部分组成的：

第一部分由编译 Compile、汇编 Assemble以及连接 Link 三个阶段组成。在这三个阶段完成之后，生成了一个可执行文件。

第二部分通过装载器 Loader 把可执行文件装载Load 到内存中。CPU从内存中读取指令和数据，来开始真正执行程序。

<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210513110713901.png" alt="image-20210513110713901" style="zoom:30%;" />



> 目标文件 Object File
>
> 可执行文件 Executable Program
>
> gcc 的 -o 参数，可以生成对应的可执行文件

#### 2.ELF格式和链接：理解链接过程

Linux 下，可执行文件和目标文件所使用的都是一种叫 **ELF（Execuatable and Linkable File Format）**的文件格式，中文名字叫**可执行与可链接文件格式**，这里面不仅存放了编译成的汇编指令，还保留了很多别的数据。

<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210513114807404.png" alt="image-20210513114807404" style="zoom:25%;" />

ELF 文件格式把各种信息，分成一个一个的 Section 保存起来。ELF 有一个基本的文件头（File Header），用来表示这个文件的基本属性，比如是否是可执行文件，对应的 CPU、操作系统等等。除了这些基本属性之外，大部分程序还有这么一些 Section：

1.**.text Section** 代码段或指令段， 用来保存程序的代码和指令

2.**.data Section** 数据段， 用来保存程序里面设置好的初始化数据信息

3.**.rel.text Section** 重定位表， 重定位表里，保留的是当前的文件里面，那些跳转地址。比如main函数里面调用了add和print两个函数，在链接发生之前，并不知道跳转到哪里，这些信息就会存储在重定位表里。

3.**.symtab Section** 符号表，保留了当前文件定义的函数名称和对应地址的地址薄。



链接器会扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。这也是为什么，可执行文件里面的函数调用的地址都是正确的。

<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210513141359502.png" alt="image-20210513141359502" style="zoom:33%;" />



在链接器把程序变成可执行文件之后，要装载器去执行程序就容易多了。装载器不再需要考虑地址跳转的问题，只需要解析 ELF 文件，把对应的指令和数据，加载到内存里面供 CPU 执行就可以了。

> Linux 下可执行文件是 ELF 文件格式，而 Windows 的可执行文件格式是一种叫作 PE（Portable Executable Format）的文件格式。Linux 下的装载器只能解析 ELF 格式而不能解析 PE 格式。
>
> Linux 下著名的开源项目 Wine，就是通过兼容 PE 格式的装载器，使得我们能直接在 Linux 下运行 Windows 程序的。而现在微软的 Windows 里面也提供了 WSL，也就是 Windows Subsystem for Linux，可以解析和加载 ELF 格式的文件。’
>
> readelf 读取出今天演示程序的符号表，看看符号表里都有哪些信息；然后通过 objdump 读取出今天演示程序的重定位表，看看里面又有哪些信息。

#### 3.推荐阅读

想要更深入了解程序的链接过程和 ELF 格式，我推荐你阅读《程序员的自我修养——链接、装载和库》的 1～4 章。这是一本难得的讲解程序的链接、装载和运行的好书。

### 五、程序装载

#### 1.装载器需要满足两个要求：

1. 可执行程序加载后占用的内存空间应该是连续的。

   执行指令的时候，程序计数器是顺序地一条一条指令执行下去。这也就意味着，这一条条指令需要连续地存储在一起。

2. 需要同时在在很多个程序，并且不能让程序自己规定在内存中加载的位置。

要满足这两个基本的要求，可以在内存里面，找到一段连续的内存空间，然后分配给装载的程序，然后把这段连续的内存空间地址，和整个程序指令里指定的内存地址做一个映射。

把指令里用到的内存地址叫作虚拟内存地址（Virtual Memory Address），实际在内存硬件里面的空间地址，我们叫物理内存地址（Physical Memory Address）。

> 程序里有指令和各种内存地址，我们只需要关心虚拟内存地址就行了。对于任何一个程序来说，它看到的都是同样的内存地址。我们维护一个虚拟内存到物理内存的映射表，这样实际程序指令执行的时候，会通过虚拟内存地址，找到对应的物理内存地址，然后执行。因为是连续的内存地址空间，所以我们只需要维护映射关系的起始地址和对应的空间大小就可以了。

#### 2.内存分段：

> 640K内存 真的不够用么？

找出一段连续的物理内存和虚拟内存地址进行映射的方法，叫**分段 Segmentation**

> 这里的段，就是指系统分配出来的那个连续的内存空间

<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210514110630013.png" alt="image-20210514110630013" style="zoom:25%;" />

##### 1.不足之处

会产生**内存碎片 Memory Fragmentation**

<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210514110842633.png" alt="image-20210514110842633" style="zoom:33%;" />



解决方法：**内存交换 Memory Swapping**

把 Python 程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里面。不过读回来的时候，我们不再把它加载到原来的位置，而是紧紧跟在那已经被占用了的 512MB 内存后面。这样，我们就有了连续的 256MB 内存空间，就可以去加载一个新的 200MB 的程序。

虚拟内存、分段，再加上内存交换，看起来似乎已经解决了计算机同时装载运行很多个程序的问题。但这三者的组合仍然会遇到一个**性能瓶颈**。硬盘的访问速度要比内存慢很多，而每一次内存交换，都需要把一大段连续的内存数据写到硬盘上。所以，如果内存交换的时候，交换的是一个很占内存空间的程序，这样整个机器都会显得卡顿。

#### 3.内存分页

既然问题出在内存碎片和内存交换的空间太大上，那么解决问题的办法就是，少出现一些内存碎片。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决这个问题。这个办法，在现在计算机的内存管理里面，就叫作**内存分页（Paging）**。

和**分段**这样分配一整段连续的空间给到程序相比，**分页**是把整个物理内存空间切成一段段固定尺寸的大小。

> 而对应的程序所需要占用的虚拟内存空间，也会同样切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。从虚拟内存到物理内存的映射，不再是拿整段连续的内存的物理地址，而是按照一个一个页来的。页的尺寸一般远远小于整个程序的大小。在 Linux 下，我们通常只设置成 4KB。你可以通过命令看看你手头的 Linux 系统设置的页的大小。
>
> `getconf PAGE_SIZE`
>
> 在进行虚拟内存和物理内存的页之间的映射之后，任何程序都不需要一次性加载完所有指令和数据，只需用到对应虚拟**内存页**里面的指令和数据时
>
> 技术方案：**加一个中间层**



通过**虚拟内存**、**内存交换**和**内存分页**这三个技术的组合，我们最终得到了一个让程序不需要考虑实际的物理内存地址、大小和当前分配空间的解决方案。我们的程序本身，就不再需要考虑对应的真实的内存地址、程序加载、内存管理等问题了。任何一个程序，都只需要把内存当成是一块完整而连续的空间来直接使用。

#### 4.推荐阅读

想要更深入地了解代码装载的详细过程，推荐你阅读《程序员的自我修养——链接、装载和库》的第 1 章和第 6 章。

### 六、动态链接

> 程序内部的”共享单车“

动态链接 Dynamic Link、静态链接 Static Link

#### 1.链接可以分动、静，共享运行省内存

在动态链接的过程中，我们想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的**共享库（Shared Libraries）**

在Window下，共享库文件是**.dll文件**   Dynamic-Link Library （DLL，动态链接库）。

在Linux下，共享文件是**.so文件** Shared Object（动态链接库）

<img src="/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210514143216479.png" alt="image-20210514143216479" style="zoom:25%;" />

#### 2.地址无关很重要，相对地址解烦恼

要想要在程序运行的时候共享代码，也有一定的要求，就是这些**机器码必须是“地址无关”的**。

> 也就是说，我们编译出来的共享库文件的指令代码，是地址无关码（Position-Independent Code）。换句话说就是，这段代码，无论加载在哪个内存地址，都能够正常执行。如果不是这样的代码，就是地址相关的代码。

而常见的**地址相关的代码**，比如绝对地址代码（Absolute Code）、利用重定位表的代码等等，都是地址相关的代码。

对于所有动态链接共享库的程序来讲，虽然我们的共享库用的都是同一段物理内存地址，但是在不同的应用程序里，它所在的虚拟内存地址是不同的。

> 我们没办法、也不应该要求动态链接同一个共享库的不同程序，必须把这个共享库所使用的虚拟内存地址变成一致。如果这样的话，我们写的程序就必须明确地知道内部的内存地址分配。

动态代码库内部的变量和函数调用都很容易解决，我们只需要使用**相对地址（Relative Address）**就好了。

>  各种指令中使用到的内存地址，给出的不是一个绝对的地址空间，而是一个相对于当前指令偏移量的内存地址。因为整个共享库是放在一段连续的虚拟内存地址中的，无论装载到哪一段地址，不同指令之间的相对地址都是不变的。

#### 3.PLT 和 GOT，动态链接的解决方案

##### 1.实现动态链接共享库

1. 首先，lib.h 定义了动态链接库的一个函数 show_me_the_money。

   ```c
   
   // lib.h
   #ifndef LIB_H
   #define LIB_H
   
   void show_me_the_money(int money);
   
   #endif
   ```

2. lib.c 包含了 lib.h 的实际实现。

   ```c
   
   // lib.c
   #include <stdio.h>
   
   void show_me_the_money(int money)
   {
       printf("Show me USD %d from lib.c \n", money);
   }
   ```

3. 然后，show_me_poor.c 调用了 lib 里面的函数。

   ```c
   // show_me_poor.c
   #include "lib.h"
   int main()
   {
       int money = 5;
       show_me_the_money(money);
   }
   ```

4. 最后，我们把 lib.c 编译成了一个动态链接库，也就是 .so 文件。

   ```shell
   $ gcc lib.c -fPIC -shared -o lib.so
   $ gcc -o show_me_poor show_me_poor.c ./lib.so
   ```

   在编译的过程中，我们指定了一个 -fPIC 的参数。这个参数其实就是 Position Independent Code 的意思，也就是我们要把这个编译成一个地址无关代码。

   然后，我们再通过 gcc 编译 show_me_poor 动态链接了 lib.so 的可执行文件。

在这些操作都完成了之后，我们把 show_me_poor 这个文件通过 objdump 出来看一下。

```shell
$ objdump -d -M intel -S show_me_poor
```

```assembly

……
0000000000400540 <show_me_the_money@plt-0x10>:
  400540:       ff 35 12 05 20 00       push   QWORD PTR [rip+0x200512]        # 600a58 <_GLOBAL_OFFSET_TABLE_+0x8>
  400546:       ff 25 14 05 20 00       jmp    QWORD PTR [rip+0x200514]        # 600a60 <_GLOBAL_OFFSET_TABLE_+0x10>
  40054c:       0f 1f 40 00             nop    DWORD PTR [rax+0x0]

0000000000400550 <show_me_the_money@plt>:
  400550:       ff 25 12 05 20 00       jmp    QWORD PTR [rip+0x200512]        # 600a68 <_GLOBAL_OFFSET_TABLE_+0x18>
  400556:       68 00 00 00 00          push   0x0
  40055b:       e9 e0 ff ff ff          jmp    400540 <_init+0x28>
……
0000000000400676 <main>:
  400676:       55                      push   rbp
  400677:       48 89 e5                mov    rbp,rsp
  40067a:       48 83 ec 10             sub    rsp,0x10
  40067e:       c7 45 fc 05 00 00 00    mov    DWORD PTR [rbp-0x4],0x5
  400685:       8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  400688:       89 c7                   mov    edi,eax
  40068a:       e8 c1 fe ff ff          call   400550 <show_me_the_money@plt>
  40068f:       c9                      leave  
  400690:       c3                      ret    
  400691:       66 2e 0f 1f 84 00 00    nop    WORD PTR cs:[rax+rax*1+0x0]
  400698:       00 00 00 
  40069b:       0f 1f 44 00 00          nop    DWORD PTR [rax+rax*1+0x0]
……
```

在 main 函数调用 show_me_the_money 的函数的时候，对应的代码

```assembly
call   400550 <show_me_the_money@plt>
```

后面有一个 @plt 的关键字，代表了我们需要从 PLT，也就是**程序链接表（Procedure Link Table）**里面找要调用的函数。对应的地址呢，则是 400550 这个地址。

目光挪到上面的 400550 这个地址，这里面又进行了一次跳转，跳转到指定的跳转地址。后面注释：`GLOBAL_OFFSET_TABLE+0x18` 全局偏移表。

在动态链接对应的共享库，我们在共享库的 data section 里面，保存了一张全局偏移表（GOT，Global Offset Table）。**虽然共享库的代码部分的物理内存是共享的，但是数据部分是各个动态链接它的应用程序里面各加载一份的。**所有需要引用当前共享库外部的地址的指令，都会查询 GOT，来找到当前运行程序的虚拟内存里的对应位置。而 GOT 表里的数据，则是在我们加载一个个共享库的时候写进去的。

不同的进程，调用同样的 lib.so，各自 GOT 里面指向最终加载的动态链接库里面的虚拟内存地址是不同的。

![image-20210514150520320](/Users/binbin.wang/Library/Application Support/typora-user-images/image-20210514150520320.png)

我们的 GOT 表位于共享库自己的数据段里。GOT 表在内存里和对应的代码段位置之间的偏移量，始终是确定的。这样，我们的共享库就是地址无关的代码，对应的各个程序只需要在物理内存里面加载同一份代码。而我们又要通过各个可执行程序在加载时，生成的各不相同的 GOT 表，来找到它需要调用到的外部变量和函数的地址。

这是一个典型的、不修改代码，而是通过修改“地址数据”来进行关联的办法。它有点像我们在 C 语言里面用函数指针来调用对应的函数，并不是通过预先已经确定好的函数名称来调用，而是利用当时它在内存里面的动态地址来调用。

> 我们终于在静态链接和程序装载之后，利用动态链接把我们的内存利用到了极致。同样功能的代码生成的共享库，我们只要在内存里面保留一份就好了。这样，我们不仅能够做到代码在开发阶段的复用，也能做到代码在运行阶段的复用。
>
> 一～五 这五讲里，已经把程序怎么从源代码变成指令、数据，并装载到内存里面，由 CPU 一条条执行下去的过程讲完了。

#### 4.推荐阅读

想要更加深入地了解动态链接，我推荐你可以读一读《程序员的自我修养：链接、装载和库》的第 7 章，里面深入地讲解了，动态链接里程序内的数据布局和对应数据的加载关系。























































































